{
  "id": "dcb902c2-f623-4782-80ca-d82f4367b76a",
  "revision": 0,
  "last_node_id": 29,
  "last_link_id": 32,
  "nodes": [
    {
      "id": 7,
      "type": "VAEDecode",
      "pos": [
        2783.722420734173,
        468.9747811081777
      ],
      "size": [
        140,
        46
      ],
      "flags": {},
      "order": 17,
      "mode": 2,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 6
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 7
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            9
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode"
      },
      "widgets_values": []
    },
    {
      "id": 5,
      "type": "DyPE_KSampler",
      "pos": [
        2693.652638832742,
        151.3797780098383
      ],
      "size": [
        289.4140625,
        198
      ],
      "flags": {},
      "order": 15,
      "mode": 2,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 20
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 17
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            6
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "DyPE_KSampler"
      },
      "widgets_values": [
        1650109550,
        "randomize",
        8,
        4.5,
        true,
        1
      ]
    },
    {
      "id": 1,
      "type": "DyPE_Model",
      "pos": [
        1964.7428700531814,
        164.33425993590876
      ],
      "size": [
        270,
        130
      ],
      "flags": {},
      "order": 0,
      "mode": 2,
      "inputs": [],
      "outputs": [
        {
          "name": "model",
          "type": "MODEL",
          "links": [
            19
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "DyPE_Model"
      },
      "widgets_values": [
        "flux1-kj-dev-fp8.safetensors",
        "none",
        true,
        "yarn"
      ]
    },
    {
      "id": 16,
      "type": "unCLIPConditioning",
      "pos": [
        2644.302471097086,
        615.6464969049807
      ],
      "size": [
        270,
        102
      ],
      "flags": {},
      "order": 13,
      "mode": 2,
      "inputs": [
        {
          "name": "conditioning",
          "type": "CONDITIONING",
          "link": 16
        },
        {
          "name": "clip_vision_output",
          "type": "CLIP_VISION_OUTPUT",
          "link": 15
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            17
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "unCLIPConditioning"
      },
      "widgets_values": [
        1,
        0
      ]
    },
    {
      "id": 9,
      "type": "DualCLIPLoader",
      "pos": [
        1862.467214289112,
        399.63501830402583
      ],
      "size": [
        270,
        130
      ],
      "flags": {},
      "order": 1,
      "mode": 2,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            11
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "DualCLIPLoader"
      },
      "widgets_values": [
        "clip_l.safetensors",
        "t5xxl_fp8_e4m3fn.safetensors",
        "flux",
        "default"
      ]
    },
    {
      "id": 12,
      "type": "CLIPVisionLoader",
      "pos": [
        1860.7709314194076,
        593.8980352623893
      ],
      "size": [
        270,
        58
      ],
      "flags": {},
      "order": 2,
      "mode": 2,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP_VISION",
          "type": "CLIP_VISION",
          "links": [
            12
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPVisionLoader"
      },
      "widgets_values": [
        "model.safetensors"
      ]
    },
    {
      "id": 13,
      "type": "CLIPVisionEncode",
      "pos": [
        2273.915662860722,
        685.3900877380017
      ],
      "size": [
        270,
        78
      ],
      "flags": {},
      "order": 10,
      "mode": 2,
      "inputs": [
        {
          "name": "clip_vision",
          "type": "CLIP_VISION",
          "link": 12
        },
        {
          "name": "image",
          "type": "IMAGE",
          "link": 13
        }
      ],
      "outputs": [
        {
          "name": "CLIP_VISION_OUTPUT",
          "type": "CLIP_VISION_OUTPUT",
          "links": [
            15
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPVisionEncode"
      },
      "widgets_values": [
        "center"
      ]
    },
    {
      "id": 10,
      "type": "SaveImage",
      "pos": [
        2976.2881690803047,
        384.37328008703963
      ],
      "size": [
        678.1073453740255,
        590.2257718073113
      ],
      "flags": {},
      "order": 19,
      "mode": 2,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 9
        }
      ],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "ComfyUI"
      ]
    },
    {
      "id": 14,
      "type": "LoadImage",
      "pos": [
        1952.5767468960403,
        703.3396483549321
      ],
      "size": [
        270,
        314
      ],
      "flags": {},
      "order": 3,
      "mode": 2,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            13
          ]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": [
        "4d7bab4c4502fcbd04e7c53758546d07.png",
        "image"
      ]
    },
    {
      "id": 8,
      "type": "VAELoader",
      "pos": [
        2619.1069911525815,
        772.6847771655044
      ],
      "size": [
        270,
        58
      ],
      "flags": {},
      "order": 4,
      "mode": 2,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            7
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "VAELoader"
      },
      "widgets_values": [
        "ae.safetensors"
      ]
    },
    {
      "id": 17,
      "type": "DyPE_Condition",
      "pos": [
        2296.304712927415,
        157.52167295561716
      ],
      "size": [
        270,
        154
      ],
      "flags": {},
      "order": 8,
      "mode": 2,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 19
        }
      ],
      "outputs": [
        {
          "name": "model",
          "type": "MODEL",
          "links": [
            20
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "DyPE_Condition"
      },
      "widgets_values": [
        "ip_adapter.safetensors",
        "flux-turbo.safetensors",
        "none",
        1,
        1
      ]
    },
    {
      "id": 11,
      "type": "DyPE_Encode",
      "pos": [
        2224.0647686114285,
        372.6151751653375
      ],
      "size": [
        426.3119897645756,
        261.66875706340795
      ],
      "flags": {},
      "order": 9,
      "mode": 2,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 11
        }
      ],
      "outputs": [
        {
          "name": "positive",
          "type": "CONDITIONING",
          "links": [
            16
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "DyPE_Encode"
      },
      "widgets_values": [
        1280,
        2048,
        "A papercut-style photo of a young man with an Asian face, wearing a white T-shirt and blue jeans, with his left hand on his hip, standing in the middle of a blue, layered, wavy-patterned papercut."
      ]
    },
    {
      "id": 19,
      "type": "DyPE_KSampler",
      "pos": [
        4729.852863293495,
        159.47312346515815
      ],
      "size": [
        289.4140625,
        198
      ],
      "flags": {},
      "order": 14,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 23
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 32
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            21
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "DyPE_KSampler"
      },
      "widgets_values": [
        1650109550,
        "randomize",
        8,
        4.5,
        true,
        1
      ]
    },
    {
      "id": 20,
      "type": "DyPE_Model",
      "pos": [
        4000.943094513936,
        172.4276053912286
      ],
      "size": [
        270,
        130
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "model",
          "type": "MODEL",
          "links": [
            30
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "DyPE_Model"
      },
      "widgets_values": [
        "flux1-kj-dev-fp8.safetensors",
        "none",
        true,
        "yarn"
      ]
    },
    {
      "id": 22,
      "type": "DualCLIPLoader",
      "pos": [
        3898.6674387498656,
        407.7283637593462
      ],
      "size": [
        270,
        130
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            31
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "DualCLIPLoader"
      },
      "widgets_values": [
        "clip_l.safetensors",
        "t5xxl_fp8_e4m3fn.safetensors",
        "flux",
        "default"
      ]
    },
    {
      "id": 29,
      "type": "DyPE_Encode",
      "pos": [
        4260.264993072181,
        380.7085206206577
      ],
      "size": [
        426.3119897645756,
        261.66875706340795
      ],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 31
        }
      ],
      "outputs": [
        {
          "name": "positive",
          "type": "CONDITIONING",
          "links": [
            32
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "DyPE_Encode"
      },
      "widgets_values": [
        1280,
        2048,
        "A papercut-style photo of a young man with an Asian face, wearing a white T-shirt and blue jeans, with his left hand on his hip, standing in the middle of a blue, layered, wavy-patterned papercut."
      ]
    },
    {
      "id": 28,
      "type": "DyPE_Condition",
      "pos": [
        4332.5049373881675,
        165.615018410937
      ],
      "size": [
        270,
        154
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 30
        }
      ],
      "outputs": [
        {
          "name": "model",
          "type": "MODEL",
          "links": [
            23
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "DyPE_Condition"
      },
      "widgets_values": [
        "none",
        "flux-turbo.safetensors",
        "none",
        1,
        1
      ]
    },
    {
      "id": 27,
      "type": "VAELoader",
      "pos": [
        4333.516449094702,
        703.9720798792987
      ],
      "size": [
        270,
        58
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            22
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "VAELoader"
      },
      "widgets_values": [
        "ae.safetensors"
      ]
    },
    {
      "id": 18,
      "type": "VAEDecode",
      "pos": [
        4732.522635423076,
        438.6651051927354
      ],
      "size": [
        140,
        46
      ],
      "flags": {},
      "order": 16,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 21
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 22
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            29
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode"
      }
    },
    {
      "id": 25,
      "type": "SaveImage",
      "pos": [
        4902.576385686707,
        411.005995102652
      ],
      "size": [
        678.1073453740255,
        590.2257718073113
      ],
      "flags": {},
      "order": 18,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 29
        }
      ],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "ComfyUI"
      ]
    }
  ],
  "links": [
    [
      6,
      5,
      0,
      7,
      0,
      "LATENT"
    ],
    [
      7,
      8,
      0,
      7,
      1,
      "VAE"
    ],
    [
      9,
      7,
      0,
      10,
      0,
      "IMAGE"
    ],
    [
      11,
      9,
      0,
      11,
      0,
      "CLIP"
    ],
    [
      12,
      12,
      0,
      13,
      0,
      "CLIP_VISION"
    ],
    [
      13,
      14,
      0,
      13,
      1,
      "IMAGE"
    ],
    [
      15,
      13,
      0,
      16,
      1,
      "CLIP_VISION_OUTPUT"
    ],
    [
      16,
      11,
      0,
      16,
      0,
      "CONDITIONING"
    ],
    [
      17,
      16,
      0,
      5,
      1,
      "CONDITIONING"
    ],
    [
      19,
      1,
      0,
      17,
      0,
      "MODEL"
    ],
    [
      20,
      17,
      0,
      5,
      0,
      "MODEL"
    ],
    [
      21,
      19,
      0,
      18,
      0,
      "LATENT"
    ],
    [
      22,
      27,
      0,
      18,
      1,
      "VAE"
    ],
    [
      23,
      28,
      0,
      19,
      0,
      "MODEL"
    ],
    [
      29,
      18,
      0,
      25,
      0,
      "IMAGE"
    ],
    [
      30,
      20,
      0,
      28,
      0,
      "MODEL"
    ],
    [
      31,
      22,
      0,
      29,
      0,
      "CLIP"
    ],
    [
      32,
      29,
      0,
      19,
      1,
      "CONDITIONING"
    ]
  ],
  "groups": [
    {
      "id": 1,
      "title": "ip adapter",
      "bounding": [
        1772.45499207235,
        0.1169814658728825,
        1979.7693582441075,
        1102.5795869455212
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 2,
      "title": "txt2img",
      "bounding": [
        3808.655216533104,
        8.210326921192703,
        1979.7693582441075,
        1102.5795869455212
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.5209868481924389,
      "offset": [
        -2060.618689500121,
        294.38050543767514
      ]
    },
    "frontendVersion": "1.28.8",
    "VHS_latentpreview": false,
    "VHS_latentpreviewrate": 0,
    "VHS_MetadataImage": true,
    "VHS_KeepIntermediate": true
  },
  "version": 0.4
}